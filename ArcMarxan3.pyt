import arcpy
import os, csv, datetime, inspect, time
import math, subprocess, shutil, glob
import matplotlib.pyplot as plt
import numpy as np

"""
/***************************************************************************
 ArcMarxan
                             -------------------
        begin                : 2016-08-29
        updated              : 2020-05-07
        copyright            : (C) 2016 by Apropos Information Systems Inc.
        email                : info@aproposinfosystems.com
 ***************************************************************************/

/***************************************************************************
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
 *   the Free Software Foundation; either version 2 of the License, or     *
 *   any later version.                                                    *
 *                                                                         *
 ***************************************************************************/
"""

class Toolbox(object):
    def __init__(self):
        """Define the toolbox (the name of the toolbox is the name of the
        .pyt file)."""
        self.label = "ArcMarxan Toolbox (2.0.2)"
        self.alias = "arcmarxan"

        # List of tool classes associated with this toolbox
        self.tools = [MarxanProject,Boundary,Features,PlanningUnits,SelectedSummary,\
                      CalibrateSPF,EstimateBLM,GraphBLM,CalibrateIterations]

#
# input.dat creation tool
#
class MarxanProject(object):
    def __init__(self):
        """Define the tool (tool name is the name of the class)."""
        self.label = "Create Input File and Folders"
        self.description = "Create input.dat file and marxan project folders. This input.dat file can be edited with a text editor (eg. NotePad) after creation."
        self.canRunInBackground = False
        self.category = "Create Project"

    def getParameterInfo(self):
        """Define parameter definitions"""
       
        # output folder
        output_folder = arcpy.Parameter(
            displayName="Marxan project folder (folder for input.dat and input and output folders)",
            name="output_folder",
            datatype="DEFolder",
            parameterType="Required",
            direction="Input")

        params = [output_folder]
        return params

    def isLicensed(self):
        """Set whether tool is licensed to execute."""
        return True

    def updateParameters(self, parameters):
        """Modify the values and properties of parameters before internal
        validation is performed.  This method is called whenever a parameter
        has been changed."""
        # process fields to ensure that only common fields are kept and
        # only fields of the appropriate type for the planning unit id
        return

    def updateMessages(self, parameters):
        """Modify the messages created by internal validation for each tool
        parameter.  This method is called after internal validation."""
        return

    def execute(self, parameters, messages):
        """The source code of the tool."""
        paramAsString = parameters[0].valueAsText
        baseDir = paramAsString.replace("\\","/")
        if os.path.exists(baseDir):
            iDir = os.path.join(baseDir,'input')
            if not os.path.exists(iDir):
                os.mkdir(iDir)
            oDir = os.path.join(baseDir,'output')
            if not os.path.exists(oDir):
                os.mkdir(oDir)
            puDir = os.path.join(baseDir,'pu')
            if not os.path.exists(puDir):
                os.mkdir(puDir)
            repDir = os.path.join(baseDir,'report')
            if not os.path.exists(repDir):
                os.mkdir(repDir)
            iName = os.path.join(baseDir,'input.dat')
            self.createInputFile(iName)
        else:
            arcpy.AddError('Folder not found %s' % baseDir)
        
        return

    def createInputFile(self,outFName):

            
        f = open(outFName, 'w')
        creditText = "Input file for Annealing program.\n\n"
        creditText += "This file generated by ArcMarxan Toolbox version 1.0.3\n" 
        creditText += "created by Apropos Information Systems Inc.\n\n"
        f.write(creditText)
        f.write("General Parameters\n")
        f.write("VERSION %s\n" % '0.1')
        f.write("BLM %s\n" % formatAsME(1.0))
        f.write("PROP %s\n" % formatAsME(0.5))
        f.write("RANDSEED %d\n" % -1)
        f.write("NUMREPS %d\n" % 100)
        f.write("\nAnnealing Parameters\n")
        f.write("NUMITNS %d\n" % 1000000)
        f.write("STARTTEMP %s\n" % formatAsME(-1.0))
        f.write("COOLFAC %s\n" % formatAsME(-1.0))
        f.write("NUMTEMP %d\n" % 10000)
        f.write("\nCost Threshold\n")
        f.write("COSTTHRESH %s\n" % formatAsME(0.0))
        f.write("THRESHPEN1 %s\n" % formatAsME(0.0))
        f.write("THRESHPEN2 %s\n" % formatAsME(0.0))
        f.write("\nInput Files\n")
        f.write("INPUTDIR %s\n" % 'input')
        f.write("SPECNAME %s\n" % 'spec.dat')
        f.write("PUNAME %s\n" % 'pu.dat')
        f.write("PUVSPRNAME %s\n" % 'puvsp.dat')
        f.write("BOUNDNAME %s\n" % 'bound.dat')
        f.write("MATRIXSPORDERNAME %s\n" % 'puvsp_sporder.dat')
        f.write("\nSave Files\n")
        f.write("SCENNAME %s\n" % 'output')
        f.write("SAVERUN %d\n" % 3)
        f.write("SAVEBEST %d\n" % 3)
        f.write("SAVESUMMARY %d\n" % 3)
        f.write("SAVESCEN %d\n" % 3)
        f.write("SAVETARGMET %d\n" % 3)
        f.write("SAVESUMSOLN %d\n" % 3)
        f.write("SAVELOG %d\n" % 3)
        f.write("SAVESNAPSTEPS %d\n" % 0)
        f.write("SAVESNAPCHANGES %d\n" % 0)
        f.write("SAVESNAPFREQUENCY %d\n" % 0)
        f.write("OUTPUTDIR %s\n" % 'output')
        f.write("\nProgram control.\n" )
        f.write("RUNMODE %d\n" % 1)
        f.write("MISSLEVEL %s\n" % formatAsME(0.95))
        f.write("ITIMPTYPE %d\n" % 1)
        f.write("HEURTYPE %d\n" % -1)
        f.write("CLUMPTYPE %d\n" % 0)
        f.write("VERBOSITY %d\n" % 2)
        f.write("SAVESOLUTIONSMATRIX %s\n\n" % '3')
        f.close()
        
#
# bound.dat creation tool
#
class Boundary(object):
    def __init__(self):
        """Define the tool (tool name is the name of the class)."""
        self.label = "Export Boundary File"
        self.description = "Create the bound.dat file. Once created this file does not require editing."
        self.canRunInBackground = False
        self.category = "Export Input Files"

    def getParameterInfo(self):
        """Define parameter definitions"""
        # boundary layer 
        boundary_layer = arcpy.Parameter(
            displayName="Planning unit layer (source of bound.dat file)",
            name="boundary_layer",
            datatype="GPFeatureLayer",
            parameterType="Required",
            direction="Input")
        boundary_layer.filter.list = ["Polygon"]
        
        # field name 
        pu_field = arcpy.Parameter(
            displayName="Planning unit id field",
            name="pu_field",
            datatype="Field",
            parameterType="Required",
            direction="Input")
        pu_field.parameterDependencies = [boundary_layer.name]
        pu_field.filter.list = ["Short","Long","Double","Float"]

        # boundary method
        boundary_method = arcpy.Parameter(
            displayName="Boundary method (how will lengths between planning units be set)",
            name="boundary_method",
            datatype="GPString",
            parameterType="Required",
            direction="Input")
        boundary_method.filter.list = ["Single Value","Measured","Weighted","Field"]
        boundary_method.value = "Single Value"
        
        # boundary treatment
        boundary_treatment = arcpy.Parameter(
            displayName="Boundary treatment (how values for PUs on perimeter of study area will be set)",
            name="boundary_treatment",
            datatype="GPString",
            parameterType="Required",
            direction="Input")
        boundary_treatment.filter.list = ["Full Value","Half Value","Exclude"]
        boundary_treatment.value = "Full Value"
            
        # boundary value
        boundary_value = arcpy.Parameter(
            displayName="Boundary value (value for all boundaries regardless of measured length)",
            name="boundary_value",
            datatype="GPDouble",
            parameterType="Optional",
            direction="Input",
            enabled=False)
        
        # field name 
        calc_field_name = arcpy.Parameter(
            displayName="Calculation field (field to weight or assign boundary lengths)",
            name="calc_field_name",
            datatype="Field",
            parameterType="Optional",
            direction="Input",
            enabled=False)
        calc_field_name.parameterDependencies = [boundary_layer.name]
        calc_field_name.filter.list = ["Short","Long","Double","Float"]
        
        # field calculation
        field_calc_method = arcpy.Parameter(
            displayName="Calculation method (how to assign boundary length if values between adjacent planning units differ)",
            name="field_calc_method",
            datatype="GPString",
            parameterType="Optional",
            direction="Input")
        field_calc_method.filter.list = ["Mean","Maximum","Minimum"]
        field_calc_method.value = "Mean"

        # output folder
        marxan_input_folder = arcpy.Parameter(
            displayName="Marxan input folder (place to write bound.dat file)",
            name="marxan_input_folder",
            datatype="DEFolder",
            parameterType="Required",
            direction="Input")
            
        params = [boundary_layer, pu_field, boundary_method, boundary_treatment, boundary_value, calc_field_name, field_calc_method, marxan_input_folder]
        return params

    def isLicensed(self):
        """Set whether tool is licensed to execute."""
        return True

    def updateParameters(self, parameters):
        """Modify the values and properties of parameters before internal
        validation is performed.  This method is called whenever a parameter
        has been changed."""
        
        # convert paramters array to named values for code clarity
        boundary_method = parameters[2]
        boundary_treatment = parameters[3]
        boundary_value = parameters[4]
        calc_field_name = parameters[5]
        field_calc_method = parameters[6]
        
        if boundary_method.value:
            if boundary_method.valueAsText == "Single Value":
                boundary_value.enabled = True
                if boundary_value.value is None:
                    boundary_value.value = 1.0
                calc_field_name.enabled = False
                field_calc_method.enabled = False
            else:
                boundary_value.enabled = False
                boundary_value.value = None
                if boundary_method.valueAsText in ["Weighted","Field"]:
                    calc_field_name.enabled = True
                    field_calc_method.enabled = True
                else: # is Measured
                    calc_field_name.enabled = False
                    field_calc_method.enabled = False
                    calc_field_name.value = ""
        return

    def updateMessages(self, parameters):
        """Modify the messages created by internal validation for each tool
        parameter.  This method is called after internal validation."""
        
        # convert paramters array to named values for code clarity
        boundary_method = parameters[2]
        boundary_treatment = parameters[3]
        boundary_value = parameters[4]
        calc_field_name = parameters[5]
        field_calc_method = parameters[6]
        
        # force values for optional fields based on boundary_method
        if boundary_method.value:
            if boundary_method.valueAsText in ["Weighted","Field"]:
                if not calc_field_name.value:
                    calc_field_name.setErrorMessage(
                        "Must selected field if using weighted or field method")
            if boundary_method.valueAsText == "Single Value":
                if not boundary_value.value:
                    boundary_value.setErrorMessage(
                        "Must set value if using single value method")
                        
        return

    def execute(self, parameters, messages):
        """The source code of the tool."""

        #
        # The approach is straightforward. Marxan must account for outer boundaries therefore
        # a new layer must be created which has an outer boundary. The natural way to do this is
        # to dissolve the pu layer, then buffer it and union the result with the original pu layer.
        # The next step is to set the PUID of the outer buffer to -1 as -1 is not a permitted pu id 
        # in Marxan. Then the arcpy polygon neighbors analysis runs and gives us a table. When one of 
        # the puid's equals -1 then that indicates an outer boundary and the id is set to match the 
        # other id and thus becomes the "self" boundary. The end result is sorted and written to disk.
        #
        
        # convert paramters array to named values for code clarity
        boundary_layer = parameters[0].valueAsText
        pu_field = parameters[1].valueAsText
        boundary_method = parameters[2].valueAsText
        boundary_treatment = parameters[3].valueAsText
        boundary_value = parameters[4].value
        calc_field_name = parameters[5].valueAsText
        field_calc_method = parameters[6].valueAsText
        marxan_input_folder = parameters[7].valueAsText
        
        # dissolve the pulayer
        #dissolveFeatClass = arcpy.env.workspace + "\\amt_temp_dissolve"
        #arcpy.Dissolve_management(boundary_layer, dissolveFeatClass)
        
        # buffer and dissolve layer in one step
        buffFeatClass = arcpy.env.workspace + "\\amt_temp_buffer"
        arcpy.Buffer_analysis(boundary_layer, buffFeatClass, '100 Meters', dissolve_option="ALL")
        # union buffered layer with the pulayer and delete temp source
        unionFeatClass = arcpy.env.workspace + "\\amt_temp_union"
        arcpy.Union_analysis([buffFeatClass, boundary_layer], unionFeatClass)
        arcpy.Delete_management(buffFeatClass)
        # update planning unit id to equal -1 
        # based on knowledge that FID_boundary_layer field will be set to -1 or 0 because 
        # the field didn't exist in the source layer for the boundary layer
        field_names = [f.name for f in arcpy.ListFields(unionFeatClass)]
        with arcpy.da.UpdateCursor(unionFeatClass,[field_names[5],pu_field]) as cursor:
            for row in cursor:
                if row[0] == -1 or row[0] == 0:
                    row[1] = -1
                    cursor.updateRow(row)
                    break
        # get boundaries and lengths
        outDBF = os.path.join(marxan_input_folder,'tempBound.dbf')
        if boundary_method in ["Weighted","Field"]:
            arcpy.PolygonNeighbors_analysis(unionFeatClass,outDBF,[pu_field,calc_field_name],both_sides="NO_BOTH_SIDES",out_linear_units="METERS")
        else:
            arcpy.PolygonNeighbors_analysis(unionFeatClass,outDBF,[pu_field],both_sides="NO_BOTH_SIDES",out_linear_units="METERS")
        boundList = []
        x = 0
        for row in arcpy.da.SearchCursor(outDBF,'*'):
            x += 1
            id1 = int(row[1])
            id2 = int(row[2])
            if id1 == -1:
                id1 = id2
            if boundary_method in ["Weighted","Field"]:
                nodes = row[6]
                sideLen = row[5]
            else:
                nodes = row[4]
                sideLen = row[3]
            # note: node > 0 means a touching corner, not a touching side
            if nodes == 0 and sideLen > 0:
                if boundary_method in ["Weighted","Field"]:
                    if id1 == id2 and int(row[1]) == -1:
                        # note this is for the perimeter where the buffered calc field value is zero 
                        # and so the difference method will fail
                        fValue = row[4]
                    else:
                        if field_calc_method == 'Mean':
                            fValue = (row[3]+row[4])/2.0
                        elif field_calc_method == 'Maximum':
                            if row[3] > row[4]:
                                fValue = row[3]
                            else:
                                fValue = row[4]
                        else:
                            if row[3] < row[4]:
                                fValue = row[3]
                            else:
                                fValue = row[4]
                if boundary_method == 'Measured':
                    bValue = sideLen
                elif boundary_method == 'Weighted':
                    bValue = sideLen * fValue
                elif boundary_method == 'Field':
                    bValue = fValue
                elif boundary_method == 'Single Value':
                    bValue = boundary_value
                # deal with boundary units special cases
                if id1 == id2:
                    if boundary_treatment in ["Full Value","Half Value"]:
                        if boundary_treatment == "Half Value":
                            bValue = bValue / 2.0
                        boundList.append([int(id1),int(id2),bValue])
                else:
                    boundList.append([int(id1),int(id2),bValue])
        boundList.sort()
        # convert to bound.dat file
        oFileName = os.path.join(marxan_input_folder,'bound.dat')
        oFile = open(oFileName,'w')
        oFile.write('id1\tid2\tboundary\n')
        for rec in boundList:
            oFile.write('%d\t%d\t%f\n' % (rec[0],rec[1],rec[2]))   
        oFile.close()
        arcpy.Delete_management(outDBF)
        arcpy.Delete_management(unionFeatClass)
        return

#
# spec.dat, puvsp.dat and puvsp_sporder.dat creation tool
#
class Features(object):
    def __init__(self):
        """Define the tool (tool name is the name of the class)."""
        self.label = "Export Feature Files"
        self.description = "Create spec.dat, puvsp.dat and puvsp_sporder.dat files. The spec.dat file will need to be edited manually after creation using a spreadsheet program. See documentation for more details."
        self.canRunInBackground = False
        self.category = "Export Input Files"

    def getParameterInfo(self):
        """Define parameter definitions"""
       
        # pu layer
        pu_layer = arcpy.Parameter(
            displayName="Planning unit layer (with feature / species values)",
            name="pu_layer",
            datatype="GPFeatureLayer",
            parameterType="Required",
            direction="Input")
        pu_layer.filter.list = ["Polygon"]
        
        # pu field name 
        pu_field = arcpy.Parameter(
            displayName="Planning unit id field",
            name="pu_field",
            datatype="Field",
            parameterType="Required",
            direction="Input")
        pu_field.parameterDependencies = [pu_layer.name]
        pu_field.filter.list = ["Short","Long","Double","Float"]

        # feauture field names
        feature_field_names = arcpy.Parameter(
            displayName="Feature fields (values for each feature / species of interest)",
            name="feature_field_names",
            datatype="Field",
            parameterType="Required",
            direction="Input",
            multiValue=True)
        feature_field_names.parameterDependencies = [pu_layer.name]
        feature_field_names.filter.list = ["Short","Long","Double","Float"]

        # output folder
        marxan_input_folder = arcpy.Parameter(
            displayName="Marxan input folder (place to write spec.dat, puvsp.dat and puvsp_sporder.dat files)",
            name="marxan_input_folder",
            datatype="DEFolder",
            parameterType="Required",
            direction="Input")

        params = [pu_layer, pu_field, feature_field_names, marxan_input_folder]
        return params

    def isLicensed(self):
        """Set whether tool is licensed to execute."""
        return True

    def updateParameters(self, parameters):
        """Modify the values and properties of parameters before internal
        validation is performed.  This method is called whenever a parameter
        has been changed."""
        return

    def updateMessages(self, parameters):
        """Modify the messages created by internal validation for each tool
        parameter.  This method is called after internal validation."""
        return

    def execute(self, parameters, messages):
        """The source code of the tool."""
        pu_layer = parameters[0].valueAsText
        pu_field = parameters[1].valueAsText
        feature_field_names = parameters[2].valueAsText.split(';')
        marxan_input_folder = parameters[3].valueAsText
        # create field list
        fldsRef = []
        flds =[]
        flds.append(pu_field)
        x = 0
        for fld in feature_field_names:
            x += 1
            fldsRef.append([x,fld])
            flds.append(fld)
        # create spec.dat file
        specFName = os.path.join(marxan_input_folder,'spec.dat')
        self.createFeatFile(fldsRef,specFName)
        # create puvsp.dat and puvsp_sporder.dat files
        f1 = os.path.join(marxan_input_folder,'puvsp.dat')
        f2 = os.path.join(marxan_input_folder,'puvsp_sporder.dat')
        self.createFeatVsPUFiles(flds,fldsRef,f1,f2,pu_layer,pu_field)
        return
        
    def createFeatFile(self,fieldRefList,specFName):

        # make copy of old spec.dat file so SPF and targets are not lost
        if os.path.exists(specFName):
            nName = specFName + '.backup_%s' % datetime.datetime.now().isoformat()[:19].replace(':','').replace('-','')
            os.rename(specFName,nName)
        header = 'id\tprop\ttarget\ttargetocc\tspf\tname\n'
        f = open(specFName,'w')
        f.write(header)
        for rec in fieldRefList:
            f.write('%d\t0.0\t0.0\t0\t1.0\t%s\n' % (rec[0],rec[1]))
        f.close()
        
    def createFeatVsPUFiles(self,flds,fieldRefList,puvFName,puvSFname,pu_layer,pu_field):
    
        unOrdered = []
        # step through file and put data into unordered list
        for row in arcpy.da.SearchCursor(pu_layer,flds):
            for rec in fieldRefList:
                if float(row[flds.index(rec[1])]) > 0:
                    unOrdered.append((rec[0],int(row[flds.index(pu_field)]),float(row[flds.index(rec[1])])))
        # use numpy to sort it quickly
        dtype = [('species', int),('pu', int),('amount', float)]
        npArray = np.array(unOrdered,dtype=dtype)
        # create puvsp order
        sList = list(np.sort(npArray, order=['pu','species']))
        # write results
        puf = open(puvFName, 'w')
        puf.write("species\tpu\tamount\n")
        for rec in sList:
            puf.write('%d\t%d\t%f\n' % (rec[0],rec[1],rec[2]))
        puf.close()
        # create puvsp_sporder order
        sList = list(np.sort(npArray,order=['species','pu']))
        # write results
        spf = open(puvSFname, 'w')
        spf.write("species\tpu\tamount\n")
        for rec in sList:
            spf.write('%d\t%d\t%f\n' % (rec[0],rec[1],rec[2]))
        spf.close()
    
#
# pu.dat creation tool
#
class PlanningUnits(object):
    def __init__(self):
        """Define the tool (tool name is the name of the class)."""
        self.label = "Export Planning Unit File"
        self.description = "Create the pu.dat file. Once created this file does not require editing."
        self.canRunInBackground = False
        self.category = "Export Input Files"

    def getParameterInfo(self):
        """Define parameter definitions"""
        # pu layer 
        pu_layer = arcpy.Parameter(
            displayName="Planning unit layer",
            name="pu_layer",
            datatype="GPFeatureLayer",
            parameterType="Required",
            direction="Input")
        pu_layer.filter.list = ["Polygon"]
        
        # pu field name 
        pu_field = arcpy.Parameter(
            displayName="Planning unit id field",
            name="pu_field",
            datatype="Field",
            parameterType="Required",
            direction="Input")
        pu_field.parameterDependencies = [pu_layer.name]
        pu_field.filter.list = ["Short","Long","Double","Float"]

        # cost field name 
        cost_field = arcpy.Parameter(
            displayName="Planning unit cost field (costs for each planning unit)",
            name="cost_field",
            datatype="Field",
            parameterType="Required",
            direction="Input")
        cost_field.parameterDependencies = [pu_layer.name]
        cost_field.filter.list = ["Short","Long","Double","Float"]

        # status field name 
        status_field = arcpy.Parameter(
            displayName="Planning unit status field (status values for each planning unit)",
            name="status_field",
            datatype="Field",
            parameterType="Required",
            direction="Input")
        status_field.parameterDependencies = [pu_layer.name]
        status_field.filter.list = ["Short","Long","Double","Float"]

        # input folder
        marxan_input_folder = arcpy.Parameter(
            displayName="Marxan input folder (place to write pu.dat file)",
            name="marxan_input_folder",
            datatype="DEFolder",
            parameterType="Required",
            direction="Input")

        params = [pu_layer, pu_field, cost_field, status_field, marxan_input_folder]
        return params

    def isLicensed(self):
        """Set whether tool is licensed to execute."""
        return True

    def updateParameters(self, parameters):
        """Modify the values and properties of parameters before internal
        validation is performed.  This method is called whenever a parameter
        has been changed."""
        return

    def updateMessages(self, parameters):
        """Modify the messages created by internal validation for each tool
        parameter.  This method is called after internal validation."""
        return

    def execute(self, parameters, messages):
        """The source code of the tool."""
        pu_layer = parameters[0].valueAsText
        pu_field = parameters[1].valueAsText
        cost_field = parameters[2].valueAsText
        status_field = parameters[3].valueAsText
        marxan_input_folder = parameters[4].valueAsText
        # pull the data
        flds = []
        fld_string = ''
        for fld in arcpy.ListFields(pu_layer):
            if fld.name in [pu_field, cost_field, status_field]:
                flds.append(fld.name)
                fld_string = fld_string + ';' + fld.name
        puList = []
        for row in arcpy.da.SearchCursor(pu_layer,flds):
            puList.append([int(row[flds.index(pu_field)]),float(row[flds.index(cost_field)]),int(row[flds.index(status_field)])])
        # sort by puid and write file
        puList.sort()
        oFileName = os.path.join(marxan_input_folder,'pu.dat')
        oFile = open(oFileName,'w')
        #oFile.write(pu_layer + '\n')
        #oFile.write(fld_string + '\n')
        oFile.write('id\tcost\tstatus\n')
        for rec in puList:
            oFile.write('%d\t%f\t%d\n' % (rec[0],rec[1],rec[2]))   
        oFile.close()

        return
     
#
# summary report of selected features creation tool
#
class SelectedSummary(object):
    def __init__(self):
        """Define the tool (tool name is the name of the class)."""
        self.label = "Report Features for Selected Planning Units"
        self.description = "Create summary of results for selected planning units. The output is a .csv file that can be opened in any spreadsheet software."
        self.canRunInBackground = False
        self.category = "Report"

    def getParameterInfo(self):
        """Define parameter definitions"""
        # pu layer 
        pu_layer = arcpy.Parameter(
            displayName="Planning unit layer (with some of the planning units selected)",
            name="pu_layer",
            datatype="GPFeatureLayer",
            parameterType="Required",
            direction="Input")
        pu_layer.filter.list = ["Polygon"]
        
        # field name 
        pu_field = arcpy.Parameter(
            displayName="Planning unit id field",
            name="pu_field",
            datatype="Field",
            parameterType="Required",
            direction="Input")
        pu_field.parameterDependencies = [pu_layer.name]
        pu_field.filter.list = ["Short","Long","Double","Float"]

        # input folder
        input_folder = arcpy.Parameter(
            displayName="Marxan input folder (with spec.data and puvsp.dat files)",
            name="input_folder",
            datatype="DEFolder",
            parameterType="Required",
            direction="Input")

        # output file
        output_file = arcpy.Parameter(
            displayName="Report output file name",
            name="output_file",
            datatype="DEFile",
            parameterType="Required",
            direction="Output")
        output_file.filter.list = ['csv']
            
        params = [pu_layer,pu_field,input_folder,output_file]
        return params

    def isLicensed(self):
        """Set whether tool is licensed to execute."""
        return True

    def updateParameters(self, parameters):
        """Modify the values and properties of parameters before internal
        validation is performed.  This method is called whenever a parameter
        has been changed."""
        return

    def updateMessages(self, parameters):
        """Modify the messages created by internal validation for each tool
        parameter.  This method is called after internal validation."""
        return

    def execute(self, parameters, messages):
        """The source code of the tool."""
        pu_layer = parameters[0].valueAsText
        pu_field = parameters[1].valueAsText
        input_folder = parameters[2].valueAsText
        output_file = parameters[3].valueAsText
        # 
        # step 1 - get field location and PU Id list
        #
        flds = []
        fld_string = ''
        puCount = int(arcpy.GetCount_management(pu_layer).getOutput(0))
        if puCount == 0:
            return
        for fld in arcpy.ListFields(pu_layer):
            if fld.name in [pu_field]:
                flds.append(fld.name)
                fld_string = fld_string + ';' + fld.name
        puIdList = []
        for row in arcpy.da.SearchCursor(pu_layer,flds):
            puIdList.append(int(row[flds.index(pu_field)]))
        # sort by puid 
        puIdList.sort()
        puSet = set(puIdList)
        # 
        # step 2 - read spec file to get internal feature ids
        #
        specFile = os.path.join(input_folder,'spec.dat')
        if os.path.exists(specFile):
            sniffer = csv.Sniffer()
            f = open(specFile,'r')
            contents = f.readline()
            dialect = sniffer.sniff(contents)
            f.close()
            if dialect.delimiter not in (',','\t'):
                messages.addErrorMessage('spec.dat format not recognized')
                raise arcpy.ExecuteError
            specRecs = {}
            with open(specFile,'r') as csvfile:
                qmdReader = csv.DictReader(csvfile,delimiter=dialect.delimiter)            
                for row in qmdReader:
                    specRecs[int(row['id'])] = row['name']
        else:
            raise Exception
            pass 
            # should raise error here
        # 
        # step 3 - read puvsp file 
        #
        # aggregate data
        puvspFile = os.path.join(input_folder,'puvsp.dat')
        if os.path.exists(puvspFile):
            # now read through the contents
            featSummary = {}
            f = open(puvspFile,'r')
            sniffer = csv.Sniffer()
            contents = f.readline()
            dialect = sniffer.sniff(contents)
            f.close()           
            with open(puvspFile,'r') as csvfile:
                qmdReader = csv.reader(csvfile,delimiter=dialect.delimiter)
                next(qmdReader)
                for line in qmdReader:
                    if int(line[1]) in puSet:
                        if line[0] in featSummary:
                            featSummary[line[0]][0] += 1
                            featSummary[line[0]][1] += float(line[2])
                        else:
                            featSummary[line[0]] = [1,float(line[2])]
        else:
            raise Exception
            pass 
        # convert to list to sort
        summaryList = [[int(key),value[0],value[1]] for key, value in featSummary.iteritems()]
        summaryList.sort()
        # 
        # step 4 - write file
        #
        # write report
        f = open(output_file,'w')
        f.write('featureId,featureName,featureCount,selectedPuCount,occurrencePercent,featureSum\n')
        for rec in summaryList:
            f.write('%d,%s,%d,%d,%f,%f\n' % (rec[0],specRecs[rec[0]],rec[1],puCount,float(rec[1])/float(puCount)*100,rec[2]) )
        f.close()

        return
        
#
# SPF Calibration tool
#
class CalibrateSPF(object):
    def __init__(self):
        """Define the tool (tool name is the name of the class)."""
        self.label = "Calibrate SPF"
        self.description = "Adjust SPF values to ensure that targets are met."
        self.canRunInBackground = False
        self.category = "Refine Results"

    def getParameterInfo(self):
        """Define parameter definitions"""
       
        # marxan executable
        marxan_exe = arcpy.Parameter(
            displayName="Marxan executable file",
            name='marxan_exe',
            datatype="DEFile",
            parameterType="Required",
            direction="Input")
        #marxan_exe.filter.list = ["exe"]
        #
        # project folder
        project_folder = arcpy.Parameter(
            displayName="Marxan project folder (where input.dat file is located)",
            name="project_folder",
            datatype="DEFolder",
            parameterType="Required",
            direction="Input")
        #
        # calculation method
        calc_method = arcpy.Parameter(
            displayName="Feature SPF Adjustment Method",
            name="calc_method",
            datatype="GPString",
            parameterType="Required",
            direction="Input")
        calc_method.filter.list = ["As Group","Individually","All Together"]
        calc_method.value = "As Group"
        #
        # success target
        success_target = arcpy.Parameter(
            displayName="Target success percentage",
            name="success_target",
            datatype="GPDouble",
            parameterType="Required",
            direction="Input")
        success_target.value = 0.9
        #
        # increment value
        increment_value = arcpy.Parameter(
            displayName="Step size for SPF increases",
            name="increment_value",
            datatype="GPDouble",
            parameterType="Required",
            direction="Input")
        increment_value.value = 0.5

        params = [marxan_exe,project_folder,calc_method,success_target,increment_value]
        return params

    def isLicensed(self):
        """Set whether tool is licensed to execute."""
        return True

    def updateParameters(self, parameters):
        """Modify the values and properties of parameters before internal
        validation is performed.  This method is called whenever a parameter
        has been changed."""
        # process fields to ensure that only common fields are kept and
        # only fields of the appropriate type for the planning unit id
        return

    def updateMessages(self, parameters):
        """Modify the messages created by internal validation for each tool
        parameter.  This method is called after internal validation."""
        return

    def execute(self, parameters, messages):
        """The source code of the tool."""
        marxanExe = parameters[0].valueAsText.replace("\\","/")
        projDir = parameters[1].valueAsText.replace("\\","/")
        calcMethod = parameters[2].valueAsText
        successTarget = parameters[3].value
        incrementValue = parameters[4].value
        #
        # test input validity
        if not os.path.exists(projDir):
            arcpy.AddError('Folder not found %s' % projDir)
        if not os.path.exists(marxanExe):
            arcpy.AddError('Marxan executable %s not found' % marxanExe)
        # 
        # read basics from input.dat
        inFile = os.path.join(projDir,'input.dat')
        if os.path.exists(inFile):
            f = open(inFile,'r')
            contents = f.readlines()
            f.close()
            for line in contents:
                if 'NUMREPS' in line:
                    reps = int(line.split(' ')[1])
                if 'INPUTDIR' in line:
                    inDir = os.path.join(projDir, line.split(' ')[1].strip())
                if 'OUTPUTDIR' in line:
                    outDir = os.path.join(projDir, line.split(' ')[1].strip())
                if 'SCENNAME' in line:
                    scenName = line.split(' ')[1].strip()
        else:
            arcpy.AddError('Project folder does not contain input.dat file')
        #
        # parse spec.dat file for current species id, name and spf values
        specFile = os.path.join(inDir,'spec.dat')
        changedSpecies = []
        changedValues = []
        if os.path.exists(specFile):
            f = open(specFile,'r')
            sniffer = csv.Sniffer()
            contents = f.readline()
            dialect = sniffer.sniff(contents)
            f.close()
            if dialect.delimiter not in (',','\t'):
                arcpy.AddError('spec.dat format not recognized')
            # read now using correct dialect
            header = None
            specData = {}
            csvFile = os.path.join(inDir, 'spec.dat')
            f = open(csvFile, 'r')
            reader=csv.reader(f, delimiter=dialect.delimiter)
            for row in reader:
                if reader.line_num == 1:
                    header = row
                else:
                    if row != []:
                        specData[int(row[0])] = dict(zip(header, row))
            f.close()
            # the above generates an output that will look similar to this:
            """
            {
                '1': {'id': '1','name': 'cbncnt','prop': '0.95','spf': '1.0','target': '0.0','targetocc': '0'},
                '2': {'id': '2','name': 'traillen','prop': '0.95','spf': '1.0','target': '0.0','targetocc': '0'},
                '3': {'id': '3','name': 'irarea','prop': '0.95','spf': '1.0','target': '0.0','targetocc': '0'}
            }
            """
            arcpy.SetProgressor("step","SPF Calibration",0,100,10)
            arcpy.AddMessage("Checkign if Marxan has been run")
            arcpy.SetProgressorPosition(10)
            # check if marxan as been run yet, and if not, run it
            runMarxan = False
            fname = 'MarOptTotalAreas.csv'
            csvFile = os.path.join(projDir,fname)
            if os.path.exists(csvFile):
                lastRunTime = os.path.getmtime(csvFile)
                specFileTime = os.path.getmtime(specFile)
                if specFileTime > lastRunTime:
                    runMarxan = True
                else:
                    ofname = 'output_mv%05d.csv' % reps
                    csvFile = os.path.join(outDir,ofname)
                    if not os.path.exists(csvFile):
                        runMarxan = True
            else:
                runMarxan = True
            if runMarxan: 
                arcpy.AddMessage('Need to run Marxan to assess if targets are being met')
                arcpy.SetProgressorPosition(20)
                status, messageText = runMarxanOnce(marxanExe,projDir,outDir,scenName,reps)
                if status == 'Error':
                    arcpy.AddError(messageText)
            #
            # determine if targets can be met
            notPossibleCount, notPossibleReport = self.checkRepresentation(specData,projDir,inDir,outDir)
            arcpy.SetProgressorPosition(30)
            if notPossibleCount == 0:
                # start loop
                moreToDo = True
                modifiedFeatures = {}
                while moreToDo:
                    #
                    arcpy.AddMessage('Checking if targets were met in most recent Marxan execution')
                    # determine if targets are being met with current SPF values
                    messageText, results = self.assessTargetSuccess(specData,inDir,outDir,reps)
                    if messageText == 'Success':
                        # tally results
                        successCount = 0
                        successList = []
                        failureCount = 0
                        failureList = []
                        missingCount = 0
                        missingList = []
                        for cfk in results.keys():
                            if results[cfk][0] == -1:
                                missingCount += 1
                                missingList.append(cfk)
                            elif results[cfk][2] >= successTarget:
                                successCount +=1
                                successList.append(cfk)
                            else:
                                failureCount +=1
                                failureList.append(cfk)
                        failureList.sort()
                        successList.sort()
                        if missingCount > 0:
                            moreToDo = False
                            arcpy.AddError("The follow features target's can not be met: " + str(missingList))
                        elif failureCount == 0:
                            moreToDo = False
                        else:
                            arcpy.AddMessage('Targets were not met in most recent Marxan execution')
                            tPctMet = int(float(successCount) / (failureCount + successCount) * 100 * 0.8)
                            arcpy.SetProgressorPosition(40 + tPctMet)
                            # adjust spf values and re-run
                            if calcMethod == 'As Group':
                                for spec in failureList:
                                    arcpy.AddMessage('Adjusting SPF value for %s' % specData[spec]['name'])
                                    newSPF = self.adjustSPF(spec,incrementValue,inDir)
                                    if specData[spec]['name'] in changedSpecies:
                                        changedValues[changedSpecies.index(specData[spec]['name'])] = newSPF
                                    else:
                                        changedSpecies.append(specData[spec]['name'])
                                        changedValues.append(newSPF)
                                    modifiedFeatures[spec] = newSPF
                            elif calcMethod == 'Individually':
                                firstSpec = failureList[0]
                                arcpy.AddMessage('Adjusting SPF value for %s' % specData[firstSpec]['name'])
                                newSPF = self.adjustSPF(firstSpec,incrementValue,inDir)
                                if specData[firstSpec]['name'] in changedSpecies:
                                    changedValues[changedSpecies.index(specData[firstSpec]['name'])] = newSPF
                                else:
                                    changedSpecies.append(specData[firstSpec]['name'])
                                    changedValues.append(newSPF)
                                modifiedFeatures[firstSpec] = newSPF
                            elif calcMethod == 'All Together':
                                arcpy.AddMessage('Adjusting SPF values for all features')
                                newSPF = self.adjustSPF('--All--',incrementValue,inDir)
                                for spec in failureList:
                                    modifiedFeatures[spec] = newSPF
                                for spec in successList:
                                    modifiedFeatures[spec] = newSPF
                            status, messageText = runMarxanOnce(marxanExe,projDir,outDir,scenName,reps)
                            if status == 'Error':
                                arcpy.AddError(messageText)
                    else:
                        arcpy.AddError(results)
            else:
                arcpy.AddError('Targets can not be met for the following features:\n' + notPossibleReport)
        else:
            arcpy.AddError('%s file not found' % specFile)
        #
        # write change report
        repDir = os.path.join(projDir,'report')
        if not os.path.exists(repDir):
            os.mkdir(repDir)
        fName = os.path.join(repDir,'spf_calibration.txt')
        f = open(fName,'w')
        if calcMethod == '2':
            f.write('All feature SPF values were incremented to %f\n' % newSPF)
        else:
            f.write('The following features SPF values were altered as follows:\n')
            for x in range(len(changedSpecies)):
                f.write('%s - %f\n' % (changedSpecies[x],changedValues[x]) )
        f.close()
        arcpy.SetProgressorPosition(100)
        arcpy.AddMessage('Feature targets met. See spf_calibration.txt in report directory for details.')
        return

    #
    #
    # checkRepresentation - determines if feasible solutions are possible by checking
    #                       the targets against the total available.
    #
    def checkRepresentation(self,specData,projDir,inDir,outDir):
        #
        # determine how much stuff is available
        # read in MarOptTotalAreas.csv
        header = None
        availData = {}
        fname = 'MarOptTotalAreas.csv'
        csvFile = os.path.join(projDir,fname)
        if os.path.exists(csvFile):
            f = open(csvFile,'r')
            sniffer = csv.Sniffer()
            contents = f.readline()
            dialect = sniffer.sniff(contents)
            f.close()
            f = open(csvFile, 'r')
            reader=csv.reader(f, delimiter=dialect.delimiter)
            for row in reader:
                if reader.line_num == 1:
                    header = row
                else:
                    availData[int(row[0])] = dict(zip(header, row))
            f.close()
            #
            # determine what the targets were
            # read in one of the _mv files
            header = None
            resultsData = {}
            fname = 'output_mv%05d.csv' % 1
            csvFile = os.path.join(outDir, fname)
            if os.path.exists(csvFile):
                f = open(csvFile,'r')
                sniffer = csv.Sniffer()
                contents = f.readline()
                dialect = sniffer.sniff(contents)
                f.close()
                f = open(csvFile, 'r')
                reader=csv.reader(f, delimiter=dialect.delimiter)
                for row in reader:
                    if reader.line_num == 1:
                        header = row
                    else:
                        resultsData[int(row[0])] = dict(zip(header, row))
                f.close()
                # assess if targets are viable
                results = ''
                missingFeatures = 0
                for row in availData:
                    targetCanBeMet = True
                    if float(availData[row]['totalarea']) == 0:
                        target = float(resultsData[row]['Target'])
                        if target > 0.0:
                            targetCanBeMet = False
                        available = 0
                    else:
                        available = float(availData[row]['totalarea']) - float(availData[row]['excludedarea'])
                        target = float(resultsData[row]['Target'])
                        propMax = available / float(availData[row]['totalarea'])
                        if target > available:
                            targetCanBeMet = False
                    if not targetCanBeMet:
                        templine = 'Feature %d (%s) can not meet ' % (row,specData[row]['name'])
                        if target > 0:
                            templine = templine + 'target of %.02f. Only %.02f available or a maximum proportion of %.04f.\n' % (target,available,propMax)
                        else:
                            templine = templine + 'uncalculated target. Data for this feature appears to be missing.\n'
                        results = results + templine
                        missingFeatures += 1
            else:
                missingFeatures = 1
                results = 'Marxan output missing value files are missing or not in the correct format. Must use csv format.'
        else:
            missingFeatures = 1
            results = 'Marxan has not yet been run or run with the required inputs to assess if success is possible'
        
        return(missingFeatures,results)
    #
    # assessTargetSuccess - determines if proportion of runs meets target success rate
    #                       Note: will return results similar to:
    #                           {'Success': {1: [100, 100, 100.0], 2: [100, 100, 100.0], 3: [100, 100, 100.0]}}
    #                       Where each key is the feature id and the three values are 
    #                           - number of runs
    #                           - number of runs where targets are met
    #                           - percent of runs where targets met
    def assessTargetSuccess(self,specData,inDir,outDir,numReps):
        #
        # create a success summary dictionary
        # structure is key: [# of successes, # of runs, % success]
        successSummary = dict(zip([int(x) for x in specData.keys()], [[0,0,0] for number in range(len(specData.keys()))]))
        #
        header = None
        resultsData = []
        for x in range(int(numReps)):
            fname = 'output_mv%05d.csv' % (x+1)
            csvFile = os.path.join(outDir, fname)
            f = open(csvFile,'r')
            sniffer = csv.Sniffer()
            contents = f.readline()
            dialect = sniffer.sniff(contents)
            f.close()
            f = open(csvFile, 'r')
            reader=csv.reader(f, delimiter=dialect.delimiter)
            for row in reader:
                if reader.line_num == 1:
                    header = row
                else:
                    try:
                        if row[8] == 'yes':
                            # targets met
                            successSummary[int(row[0])][0] += 1
                            successSummary[int(row[0])][1] += 1
                            successSummary[int(row[0])][2] = float(successSummary[int(row[0])][0])/float(successSummary[int(row[0])][1])*100
                        elif row[8] == 'no':
                            # targets not met
                            successSummary[int(row[0])][1] += 1
                            if successSummary[int(row[0])][0] > 0:
                                successSummary[int(row[0])][2] = float(successSummary[int(row[0])][0])/float(successSummary[int(row[0])][1])*100
                        else:
                            if float(row[2]) > 0.0:
                                # features are missing
                                successSummary[int(row[0])][0] = -1
                            else:
                                successSummary[int(row[0])][0] += 1
                                successSummary[int(row[0])][1] += 1
                                successSummary[int(row[0])][2] = float(successSummary[int(row[0])][0])/float(successSummary[int(row[0])][1])*100
                    except:
                        retMsg = "spec.dat file doesn't match output results. Please correct before proceeding"
                        return('Error',retMsg)
            f.close()
                        
        return('Success',successSummary)
    #
    # adjustSPF - adjust SPF value for a feature
    #
    def adjustSPF(self,specId,spfStep,inDir):

        #
        # Need to rewrite this code as running on windows inserts blank spaces
        # change the writing to be similar to the original spec.dat creation code
        #
        newSPF = 0
        messageText = ''
        header = None
        specData = {}
        # read in existing spec.data file
        csvFile = os.path.join(inDir, 'spec.dat')
        f = open(csvFile,'r')
        sniffer = csv.Sniffer()
        contents = f.readline()
        dialect = sniffer.sniff(contents)
        f.close()
        f = open(csvFile, 'r')
        reader=csv.reader(f, delimiter=dialect.delimiter)
        for row in reader:
            if reader.line_num == 1:
                header = row
            else:
                specData[int(row[0])] = dict(zip(header, row))
        f.close()
        # increment values
        if specId == '--All--':
            for x in list(specData.keys()):
                newSPF = float(specData[x]['spf']) + float(spfStep)
                specData[x]['spf'] = str(newSPF)
        else:
            # increment spf value
            newSPF = float(specData[specId]['spf']) + float(spfStep)
            specData[specId]['spf'] = str(newSPF)
        # write new spec.dat file
        f = open(csvFile, 'w')
        writer = csv.writer(f, delimiter=dialect.delimiter)
        writer.writerow(header)
        rlist = list(specData.keys())
        rlist.sort()
        for row in rlist:
            outlist = []
            for fn in header:
                outlist.append(str(specData[row][fn]))
            writer.writerow(outlist)
        f.close()
        
        return(newSPF)

#
# BLM Estimation tool
#
class EstimateBLM(object):
    def __init__(self):
        """Define the tool (tool name is the name of the class)."""
        self.label = "Estimate BLM"
        self.description = "Estimate BLM sensitive range and balance point on cost vs boundary length graph."
        self.canRunInBackground = False
        self.category = "Refine Results"

    def getParameterInfo(self):
        """Define parameter definitions"""
       
        # marxan executable
        marxan_exe = arcpy.Parameter(
            displayName="Marxan executable file",
            name='marxan_exe',
            datatype="DEFile",
            parameterType="Required",
            direction="Input")
        marxan_exe.filter.list = ["exe"]
        #
        # project folder
        project_folder = arcpy.Parameter(
            displayName="Marxan project folder (where input.dat file is located)",
            name="project_folder",
            datatype="DEFolder",
            parameterType="Required",
            direction="Input")

        params = [marxan_exe,project_folder]
        return params

    def isLicensed(self):
        """Set whether tool is licensed to execute."""
        return True

    def updateParameters(self, parameters):
        """Modify the values and properties of parameters before internal
        validation is performed.  This method is called whenever a parameter
        has been changed."""
        # process fields to ensure that only common fields are kept and
        # only fields of the appropriate type for the planning unit id
        return

    def updateMessages(self, parameters):
        """Modify the messages created by internal validation for each tool
        parameter.  This method is called after internal validation."""
        return

    def execute(self, parameters, messages):
        """The source code of the tool."""
        marxanExe = parameters[0].valueAsText.replace("\\","/")
        projDir = parameters[1].valueAsText.replace("\\","/")
        #
        arcpy.SetProgressor("step","BLM Estimation",0,100,10)
        arcpy.SetProgressorPosition(5)
        arcpy.AddMessage('Reading input files')
        #
        # test validity of inputs
        if not os.path.exists(marxanExe):
            arcpy.AddError('Marxan executable file (%s) not found' % marxanExe)
        if not os.path.exists(projDir):
            arcpy.AddError('Marxan project folder (%s) not found' % projDir)
        # 
        # read basics from input.dat
        inFile = os.path.join(projDir,'input.dat')
        if os.path.exists(inFile):
            f = open(inFile,'r')
            contents = f.readlines()
            f.close()
            for line in contents:
                if 'NUMREPS' in line:
                    reps = int(line.split(' ')[1])
                if 'INPUTDIR' in line:
                    inDir = os.path.join(projDir, line.split(' ')[1].strip())
                if 'OUTPUTDIR' in line:
                    outDir = os.path.join(projDir, line.split(' ')[1].strip())
                if 'SCENNAME' in line:
                    scenName = line.split(' ')[1].strip()
        else:
            arcpy.AddError('Input folder does not contain input.dat file')
        #
        # Step 1 - Get minimum cost solution    
        # 1a. set blm to zero
        arcpy.SetProgressorPosition(5)
        arcpy.AddMessage('Starting BLM estimation')
        arcpy.AddMessage('\nFirst Marxan execution')
        arcpy.AddMessage('Setting BLM to zero (determine minimum cost unclustered solution)')
        setBLM(0.0,projDir)
        # 1b. do run
        status, messageText = runMarxanOnce(marxanExe,projDir,outDir,scenName,reps)
        if status == 'Error':
            arcpy.AddError(messageText)
        # 1c. Get cost and boundary length
        xCost, xBoundary = self.getCostBoundaryLength('calcCost',scenName,outDir,inDir)
        # Step 2 - Get minimum boundary solution
        # 2a. Set costs to zero
        arcpy.SetProgressorPosition(30)
        arcpy.AddMessage('\nSecond Marxan execution')
        arcpy.AddMessage('Setting pu cost to zero and BLM to one (determine minimum boundary clustered solution)')
        self.setCostToZero(inDir)
        setBLM(1.0,projDir)
        # 2b. do run
        status, messageText = runMarxanOnce(marxanExe,projDir,outDir,scenName,reps)
        if status == 'Error':
            arcpy.AddError(messageText)
        # 2c. get cost and boundary length
        arcpy.AddMessage('Calculating slope')
        yCost, yBoundary = self.getCostBoundaryLength('realCost',scenName,outDir,inDir)
        # Step 3 - Calculate "slope" to determine BLM
        # 3a. (step 1 cost - step 2 cost [actually zero]) / (step 1 boundary - step 2 boundary)
        arcpy.SetProgressorPosition(55)
        calcSlope = abs((xCost - yCost)/(xBoundary - yBoundary))
        # 3b. Set blm to "slope"
        arcpy.AddMessage('\nFinal Marxan execution')
        arcpy.AddMessage('Setting new BLM value')
        setBLM(calcSlope,projDir)
        # Step 4 - Restore costs and run once more
        arcpy.SetProgressorPosition(90)
        self.restoreCosts(inDir)
        abort, temp = runMarxanOnce(marxanExe,projDir,outDir,scenName,reps)
        zCost, zBoundary = self.getCostBoundaryLength('calcCost',scenName,outDir,inDir)
        bVal = abs((zCost - yCost)/(zBoundary - yBoundary))
        cVal = abs((xCost - zCost)/(xBoundary - zBoundary))
        #
        # write change report
        repDir = os.path.join(projDir,'report')
        if not os.path.exists(repDir):
            os.mkdir(repDir)
        fName = os.path.join(repDir,'blm_estimation.txt')
        f = open(fName,'w')
        f.write('BLM Estimation Results\n\n')
        f.write('Minimum Cost Unclustered Solution:\n')
        f.write('X: Cost %.01f, Boundary %.01f\n\n' % (xCost,xBoundary))
        f.write('Minimum Boundary Clustered Solution\n')
        f.write('Y: Cost %.01f, Boundary %.01f\n\n' % (yCost,yBoundary))
        f.write('Estimated Midpoint BLM: %.14f\n' % calcSlope)
        f.write('Z: Cost %.01f, Boundary %.01f\n\n' % (zCost,zBoundary))
        f.write('Estimated sensitive range of BLM is between %.14f and %.14f\n' % (bVal, cVal))
        f.close()
        #
        arcpy.SetProgressorPosition(100)
        arcpy.AddMessage('\nBLM Estimation completed. See blm_estimation.txt in report directory for details.\n')
        return
    #
    #
    # set costs to zero
    #
    def setCostToZero(self,inDir):

        # make a copy to restore later
        puFName = os.path.join(inDir,'pu.dat')
        puFNCopy = os.path.join(inDir,'pu.dat.old')
        shutil.copyfile(puFName,puFNCopy)
        # read in file
        header = None
        puData = {}
        f = open(puFName,'r')
        sniffer = csv.Sniffer()
        contents = f.readline()
        dialect = sniffer.sniff(contents)
        f.close()
        f = open(puFName, 'r')
        reader=csv.reader(f, delimiter=dialect.delimiter)
        for row in reader:
            if reader.line_num == 1:
                header = row
            else:
                if row != []:
                    puData[row[0]] = dict(zip(header, row))
        f.close()
        # write new file
        f = open(puFName, 'w')
        writer = csv.writer(f, delimiter=dialect.delimiter)
        writer.writerow(header)
        for row in puData:
            outlist = []
            for fn in header:
                if fn == 'cost':
                    outlist.append(str(0.0))
                else:
                    if row != []:
                        outlist.append(str(puData[row][fn]))
            writer.writerow(outlist)
        f.close()
    #
    #
    # get cost and boundary length 
    #
    def getCostBoundaryLength(self,param,scenName,outDir,inDir):

        header = None
        resultsData = {}
        summaryData = {}
        csvFile = os.path.join(outDir,'%s_sum.csv' % scenName)
        f = open(csvFile,'r')
        sniffer = csv.Sniffer()
        contents = f.readline()
        dialect = sniffer.sniff(contents)
        f.close()
        f = open(csvFile, 'r')
        reader=csv.reader(f, delimiter=dialect.delimiter)
        for row in reader:
            if reader.line_num == 1:
                header = row
            else:
                if row != []:
                    summaryData[row[0]] = dict(zip(header, row))
        f.close()
        #
        # process information
        cost = None
        boundary = None
        score = None
        if param == 'calcCost':
            for row in summaryData:
                if score == None:
                    score = summaryData[row]['Score']
                    cost = summaryData[row]['Cost']
                    boundary = summaryData[row]['Connectivity']
                elif summaryData[row]['Score'] < score:
                    score = summaryData[row]['Score']
                    cost = summaryData[row]['Cost']
                    boundary = summaryData[row]['Connectivity']
        elif param == 'realCost':
            solnId = 1
            for row in summaryData:
                if score == None:
                    score = summaryData[row]['Score']
                    boundary = summaryData[row]['Connectivity']
                    solnId = int(summaryData[row]['Run_Number'])
                elif summaryData[row]['Score'] < score:
                    score = summaryData[row]['Score']
                    boundary = summaryData[row]['Connectivity']
                    solnId = int(summaryData[row]['Run_Number'])
            cost = self.getRealCost(solnId,inDir,outDir,scenName)
                        
        return(float(cost),float(boundary))
    #
    #
    # get real cost - for solutions where cost has been artificially set to zero
    #
    def getRealCost(self,solnId,inDir,outDir,scenName):

        realCost = 0.0
        # open costs file
        costFN = os.path.join(inDir,'pu.dat.old')
        if os.path.exists(costFN):
            f = open(costFN,'r')
        else:
            costFN = os.path.join(inDir,'pu.dat')
            f = open(costFN,'r')
        sniffer = csv.Sniffer()
        contents = f.readline()
        dialect = sniffer.sniff(contents)
        f.close()
        cf = open(costFN,'r')
        costReader = csv.reader(cf, delimiter=dialect.delimiter)
        # open solution file
        fname = '%s_r%05d.csv' % (scenName,solnId)
        csvFile = os.path.join(outDir, fname)
        f = open(csvFile, 'r')
        sniffer = csv.Sniffer()
        contents = f.readline()
        dialect = sniffer.sniff(contents)
        f.close()
        f = open(csvFile, 'r')
        solnReader=csv.reader(f, delimiter=dialect.delimiter)
        # convert costs to dictionary
        costData = {}
        for row in costReader:
            if costReader.line_num == 1:
                header = row
            else:
                if row != []:
                    costData[row[0]] = dict(zip(header, row))
        cf.close()
        for row in solnReader:
            if solnReader.line_num == 1:
                header = row
            else:
                if row != [] and int(row[1]) == 1:
                    realCost += float(costData[row[0]]['cost'])
        f.close()
        return(realCost)
    #
    #
    # restore scenario costs
    #
    def restoreCosts(self,inDir):

        # remove old file
        puFName = os.path.join(inDir,'pu.dat')
        os.remove(puFName)
        # rename copy
        puFNCopy = os.path.join(inDir,'pu.dat.old')
        shutil.move(puFNCopy,puFName)
#
#
# BLM Graph Tool
#
class GraphBLM(object):
    def __init__(self):
        """Define the tool (tool name is the name of the class)."""
        self.label = "Graph BLM"
        self.description = "Plot a series of BLM values on cost vs boundary length line graph."
        self.canRunInBackground = False
        self.category = "Refine Results"

    def getParameterInfo(self):
        """Define parameter definitions"""
        #
        # marxan executable
        marxan_exe = arcpy.Parameter(
            displayName="Marxan executable file",
            name='marxan_exe',
            datatype="DEFile",
            parameterType="Required",
            direction="Input")
        marxan_exe.filter.list = ["exe"]
        #
        # project folder
        project_folder = arcpy.Parameter(
            displayName="Marxan project folder (where input.dat file is located)",
            name="project_folder",
            datatype="DEFolder",
            parameterType="Required",
            direction="Input")
        #
        # BLM value list
        blm_list = arcpy.Parameter(
            displayName="BLM Value List (provide a comma separated list of BLM values to graph)",
            name="blm_list",
            datatype="GPString",
            parameterType="Required",
            direction="Input")
        blm_list.value = '0.0,0.001,0.01,0.1,1.0,10,100,1000'

        params = [marxan_exe,project_folder,blm_list]
        return params

    def isLicensed(self):
        """Set whether tool is licensed to execute."""
        return True

    def updateParameters(self, parameters):
        """Modify the values and properties of parameters before internal
        validation is performed.  This method is called whenever a parameter
        has been changed."""
        # process fields to ensure that only common fields are kept and
        # only fields of the appropriate type for the planning unit id
        return

    def updateMessages(self, parameters):
        """Modify the messages created by internal validation for each tool
        parameter.  This method is called after internal validation."""
        return

    def execute(self, parameters, messages):
        """The source code of the tool."""
        marxanExe = parameters[0].valueAsText.replace("\\","/")
        projDir = parameters[1].valueAsText.replace("\\","/")
        blmList = parameters[2].valueAsText.split(',')
        blmList = [float(val) for val in blmList]
        blmList.sort()
        #
        arcpy.SetProgressor("step","Graph BLM",0,100,10)
        arcpy.SetProgressorPosition(5)
        arcpy.AddMessage('Reading input files')
        #
        # test validity of inputs
        if not os.path.exists(marxanExe):
            arcpy.AddError('Marxan executable file (%s) not found' % marxanExe)
        if not os.path.exists(projDir):
            arcpy.AddError('Marxan project folder (%s) not found' % projDir)
        #
        # ensure report folder exists
        repDir = os.path.join(projDir,'report')
        if not os.path.exists(repDir):
            os.mkdir(repDir)
        # 
        # read basics from input.dat
        inFile = os.path.join(projDir,'input.dat')
        if os.path.exists(inFile):
            f = open(inFile,'r')
            contents = f.readlines()
            f.close()
            for line in contents:
                if 'NUMREPS' in line:
                    reps = int(line.split(' ')[1])
                if 'INPUTDIR' in line:
                    inDir = os.path.join(projDir, line.split(' ')[1].strip())
                if 'OUTPUTDIR' in line:
                    outDir = os.path.join(projDir, line.split(' ')[1].strip())
                if 'SCENNAME' in line:
                    scenName = line.split(' ')[1].strip()
        else:
            arcpy.AddError('Input folder does not contain input.dat file')
        # collect the data
        boundaryList = []
        bMax = 0.0
        costList = []
        cMax = 0.0
        x = 1
        for blm in blmList:
            arcpy.SetProgressorPosition(90/len(blmList)*x)
            arcpy.AddMessage('\nRunning Marxan with BLM of %0.05f' % blm)
            # set blm
            setBLM(blm,projDir)
            # run marxan
            status, messageText = runMarxanOnce(marxanExe,projDir,outDir,scenName,reps)
            time.sleep(2)
            if status == 'Error':
                arcpy.AddError(messageText)
            # get cost and boundary length
            blmCost, blmBoundary = self.getCostBoundary(scenName,outDir,inDir)
            boundaryList.append(blmBoundary)
            costList.append(blmCost)
            x = x + 1
            # produce overshoot table and graph
            self.generateOvershootInfo(projDir,outDir,blm)
        #
        # plot the data
        arcpy.SetProgressorPosition(95)
        arcpy.AddMessage('Creating graph in project folder')
        blmGraphFile = os.path.join(repDir,'blm_graph.png')
        if os.path.exists(blmGraphFile):
            os.remove(blmGraphFile) 
        plt.clf()
        plt.close()
        plt.plot(boundaryList,costList)
        plt.scatter(boundaryList,costList)
        for x in range(len(blmList)):
            plt.annotate(str(blmList[x]),(boundaryList[x],costList[x]),textcoords='offset points',xytext=(10,0))
        plt.xlabel('Boundary')
        plt.ylabel('Cost')
        plt.savefig(blmGraphFile)
        plt.clf()
        plt.close()
        arcpy.SetProgressorPosition(100)
        arcpy.AddMessage('Done!')
        return
    #
    #
    # create overshoot table and graph
    #
    def generateOvershootInfo(self,projDir,outDir,blm):

        fList = glob.glob(outDir + '/*mv*.csv')
        # get list of missing value files
        specList = []
        specDetails = []
        for mvFile in fList:
            f = open(mvFile,'r')
            csv_reader = csv.DictReader(f)      
            # for each species process it accordingly
            for rec in csv_reader:
                if rec['Conservation Feature'] in specList:
                    idx = specList.index(rec['Conservation Feature'])
                    targetPercentage = float(rec['Amount Held']) / float(rec['Target'])
                    specDetails[idx].append(targetPercentage)
                else:
                    if float(rec['Target']) > 0.0:
                        specList.append(rec['Conservation Feature'])
                        targetPercentage = float(rec['Amount Held']) / float(rec['Target'])
                        specDetails.append([targetPercentage])
            f.close()
        # calc stats
        specStats = []
        histData = []
        for rec in specDetails:
            a = np.array(rec)
            specStats.append([np.mean(a),np.min(a),np.max(a)])
            histData.append(np.mean(a))
        # create table of information
        statsFile = 'blm%.05f_feature_stats.csv' % blm
        graphFile = 'blm%.05f_feature_hist.png' % blm
        statsFName = os.path.join(projDir,'report',statsFile)
        graphFName = os.path.join(projDir,'report',graphFile)
        f = open(statsFName,'w')
        f.write('spec,mean,min,max\n')
        for x in range(len(specList)):
            f.write('%s,%f,%f,%f\n' % (specList[x],specStats[x][0],specStats[x][1],specStats[x][2]))
        f.close()
        # create graph
        plt.clf()
        plt.close()
        plt.hist(histData)
        plt.xlabel('Achieved Proportion')
        plt.ylabel('Number of Features')
        plt.savefig(graphFName)
        plt.clf()
        plt.close()
    #
    #
    # get cost and boundary length 
    #
    def getCostBoundary(self,scenName,outDir,inDir):

        header = None
        resultsData = {}
        summaryData = {}
        csvFile = os.path.join(outDir,'%s_sum.csv' % scenName)
        f = open(csvFile,'r')
        sniffer = csv.Sniffer()
        contents = f.readline()
        dialect = sniffer.sniff(contents)
        f.close()
        f = open(csvFile, 'r')
        reader=csv.reader(f, delimiter=dialect.delimiter)
        for row in reader:
            if reader.line_num == 1:
                header = row
            else:
                if row != []:
                    summaryData[row[0]] = dict(zip(header, row))
        f.close()
        #
        # process information
        cost = None
        boundary = None
        score = None
        for row in summaryData:
            if score == None:
                score = summaryData[row]['Score']
                cost = summaryData[row]['Cost']
                boundary = summaryData[row]['Connectivity']
            elif summaryData[row]['Score'] < score:
                score = summaryData[row]['Score']
                cost = summaryData[row]['Cost']
                boundary = summaryData[row]['Connectivity']
                        
        return(float(cost),float(boundary))
#
#
# Calibrate Iterations Tool
#
class CalibrateIterations(object):
    def __init__(self):
        """Define the tool (tool name is the name of the class)."""
        self.label = "Iteration Calibration"
        self.description = "Test a series of iteration values to select an appropriate value to full explore the solution space."
        self.canRunInBackground = False
        self.category = "Refine Results"

    def getParameterInfo(self):
        """Define parameter definitions"""
        #
        # marxan executable
        marxan_exe = arcpy.Parameter(
            displayName="Marxan executable file",
            name='marxan_exe',
            datatype="DEFile",
            parameterType="Required",
            direction="Input")
        marxan_exe.filter.list = ["exe"]
        #
        # project folder
        project_folder = arcpy.Parameter(
            displayName="Marxan project folder (with input.dat)",
            name="project_folder",
            datatype="DEFolder",
            parameterType="Required",
            direction="Input")
        #
        # iteration value list
        iter_list = arcpy.Parameter(
            displayName="Iteration List (provide a comma separated list of iterations in increasing values to test)",
            name="iter_list",
            datatype="GPString",
            parameterType="Required",
            direction="Input")
        iter_list.value = '1000000,5000000,10000000'

        params = [marxan_exe,project_folder,iter_list]
        return params

    def isLicensed(self):
        """Set whether tool is licensed to execute."""
        return True

    def updateParameters(self, parameters):
        """Modify the values and properties of parameters before internal
        validation is performed.  This method is called whenever a parameter
        has been changed."""
        # process fields to ensure that only common fields are kept and
        # only fields of the appropriate type for the planning unit id
        return

    def updateMessages(self, parameters):
        """Modify the messages created by internal validation for each tool
        parameter.  This method is called after internal validation."""
        return

    def execute(self, parameters, messages):
        """The source code of the tool."""
        marxanExe = parameters[0].valueAsText.replace("\\","/")
        projDir = parameters[1].valueAsText.replace("\\","/")
        iterList = parameters[2].valueAsText.split(',')
        iterList = [int(val) for val in iterList]
        iterList.sort()
        #
        arcpy.SetProgressor("step","Iteration Calibration",0,100,10)
        arcpy.SetProgressorPosition(5)
        arcpy.AddMessage('Reading input files')
        #
        # test validity of inputs
        if not os.path.exists(marxanExe):
            arcpy.AddError('Marxan executable file (%s) not found' % marxanExe)
        if not os.path.exists(projDir):
            arcpy.AddError('Marxan project folder (%s) not found' % projDir)
        #
        # ensure report folder exists
        repDir = os.path.join(projDir,'report')
        if not os.path.exists(repDir):
            os.mkdir(repDir)
       # 
        # read basics from input.dat
        inFile = os.path.join(projDir,'input.dat')
        if os.path.exists(inFile):
            f = open(inFile,'r')
            contents = f.readlines()
            f.close()
            for line in contents:
                if 'NUMREPS' in line:
                    reps = int(line.split(' ')[1])
                if 'INPUTDIR' in line:
                    inDir = os.path.join(projDir, line.split(' ')[1].strip())
                if 'OUTPUTDIR' in line:
                    outDir = os.path.join(projDir, line.split(' ')[1].strip())
                if 'SCENNAME' in line:
                    scenName = line.split(' ')[1].strip()
        else:
            arcpy.AddError('Input folder does not contain input.dat file')
        #
        itvLen = len(iterList)
        x = 1
        results = {}
        recIt = None
        recMean = 0.0
        for iVal in iterList:
            newV = 5 + int(float(x)/itvLen*100*0.70)
            arcpy.SetProgressorPosition(newV)
            arcpy.AddMessage('\nCalibrating iterations. Executing Marxan %d of %d times' % (x,itvLen))
            arcpy.AddMessage('Trying %d iterations' % int(iVal))
            self.adjustIterationValue(float(iVal),projDir)
            status, messageText = runMarxanOnce(marxanExe,projDir,outDir,scenName,reps)
            time.sleep(2)
            if status == 'Error':
                arcpy.AddError(messageText)
            ifname = os.path.join(outDir,'%s_sum.csv' % scenName)
            ofname = os.path.join(repDir,'output_sum_i'+str(x)+'.txt')
            shutil.copy2(ifname,ofname)
            results[iVal] = self.calcMeanVariance(ofname)
            if recIt == None:
                recIt = iVal
                recMean = results[iVal][0]
            elif results[iVal][0] < recMean:
                recIt = iVal
                recMean = results[iVal][0]
            x = x + 1
        # calculate means and variances of costs
        arcpy.AddMessage('Calibrating iterations. Comparing results.')
        plts = []
        plt.clf()
        plt.close()
        for x in range(len(iterList)):
            fName = os.path.join(repDir,'output_sum_i'+str(x+1)+'.txt')
            f = open(fName, 'r')
            sniffer = csv.Sniffer()
            contents = f.readline()
            dialect = sniffer.sniff(contents)
            f.close()
            f = open(fName,'r')
            reader = csv.reader(f,delimiter=dialect.delimiter)
            costs = []
            for row in reader:
                if reader.line_num == 1:
                    header = row
                else:
                    costs.append(float(row[2]))
            f.close()
            a = np.array(costs)
            a1 = a/min(a)*100
            # create cdf plot
            a1.sort()
            plts.append( plt.plot(a1, np.arange(len(a1))) ) 
        arcpy.SetProgressorPosition(80)
        # write plot to file
        plt.legend((a[0] for a in plts), iterList)
        cdfImageFile = os.path.join(repDir,'cost_cdf_plot.png')
        if os.path.exists(cdfImageFile):
            os.remove(cdfImageFile)
        plt.savefig(cdfImageFile)
        plt.clf()
        plt.close()
        # calculate means and variances of scores
        plts = []
        plt.clf()
        plt.close()
        for x in range(len(iterList)):
            fName = os.path.join(repDir,'output_sum_i'+str(x+1)+'.txt')
            f = open(fName, 'r')
            sniffer = csv.Sniffer()
            contents = f.readline()
            dialect = sniffer.sniff(contents)
            f.close()
            f = open(fName,'r')
            reader = csv.reader(f,delimiter=dialect.delimiter)
            scores = []
            for row in reader:
                if reader.line_num == 1:
                    header = row
                else:
                    scores.append(float(row[1]))
            f.close()
            a = np.array(scores)
            a1 = a/min(a)*100
            # create cdf plot
            a1.sort()
            plts.append( plt.plot(a1, np.arange(len(a1))) )
        arcpy.SetProgressorPosition(88)
        # write plot to file
        plt.legend((a[0] for a in plts), iterList)
        cdfImageFile = os.path.join(repDir,'score_cdf_plot.png')
        if os.path.exists(cdfImageFile):
            os.remove(cdfImageFile)
        plt.savefig(cdfImageFile)
        plt.clf()
        plt.close()
        # calculate means and variances of boundary
        plts = []
        plt.clf()
        plt.close()
        for x in range(len(iterList)):
            fName = os.path.join(repDir,'output_sum_i'+str(x+1)+'.txt')
            f = open(fName, 'r')
            sniffer = csv.Sniffer()
            contents = f.readline()
            dialect = sniffer.sniff(contents)
            f.close()
            f = open(fName,'r')
            reader = csv.reader(f,delimiter=dialect.delimiter)
            boundaries = []
            for row in reader:
                if reader.line_num == 1:
                    header = row
                else:
                    boundaries.append(float(row[4]))
            f.close()
            a = np.array(boundaries)
            a1 = a/min(a)*100
            # create cdf plot
            a1.sort()
            plts.append( plt.plot(a1, np.arange(len(a1))) )
        arcpy.SetProgressorPosition(95)
        # write plot to file
        plt.legend((a[0] for a in plts), iterList)
        cdfImageFile = os.path.join(repDir,'boundary_cdf_plot.png')
        if os.path.exists(cdfImageFile):
            os.remove(cdfImageFile)
        plt.savefig(cdfImageFile)
        plt.clf()
        plt.close()
        # create file with results
        resultsFile = os.path.join(repDir,'iteration_results.csv')
        if os.path.exists(resultsFile):
            os.remove(resultsFile)
        f = open(resultsFile,'w')
        f.write('iteration,cdfCostMean,cdfCostVar,costMean,costVar,cdfScoreMean,cdfScoreVar,scoreMean,scoreVar,cdfBndMean,cdfBndVar,bndMean,bndVar\n')
        for x in iterList:
            outLine = '%d,%.05f,%.05f,%.05f,%.05f,%.05f,%.05f,%.05f,%.05f,%.05f,%.05f,%.05f,%.05f\n' % (int(x),results[x][0],results[x][1],results[x][2],results[x][3],results[x][4],results[x][5],results[x][6],results[x][7],results[x][8],results[x][9],results[x][10],results[x][11])
            f.write(outLine)
        f.close()
        #
        messageText = 'Iteration Analysis completed\n'
        messageText += "In the report directory you will find the following items:\n"
        messageText += "Graphs called cost_cdf_plot.png, score_cdf_plot.png and boundary_cdf_plot.png\n"
        messageText += "A csv file called iteration_results.csv\n\n"
        messageText += 'Please review graphs and results to deterimine the best iteration value.\n'
        messageText += 'An iteration value to consider is %s. \n' % recIt
        arcpy.SetProgressorPosition(100)
        arcpy.AddMessage(messageText)
        return
    #
    # calculate mean and variance
    #
    def calcMeanVariance(self,fName):
        f = open(fName, 'r')
        sniffer = csv.Sniffer()
        contents = f.readline()
        dialect = sniffer.sniff(contents)
        f.close()
        f = open(fName,'r')
        reader = csv.reader(f,delimiter=dialect.delimiter)
        costs = []
        scores = []
        boundaries = []
        for row in reader:
            if reader.line_num == 1:
                header = row
            else:
                costs.append(float(row[2]))
                scores.append(float(row[1]))
                boundaries.append(float(row[4]))
        f.close()
        # costs
        a = np.array(costs)
        a1 = a/min(a)*100
        cdfCostMean = np.mean(a1)
        cdfCostVar = np.var(a1)
        costMean = np.mean(a)
        costVar = np.var(a)
        # scores
        b = np.array(scores)
        b1 = b/min(b)*100
        cdfScoreMean = np.mean(b1)
        cdfScoreVar =np.var(b1)
        scoreMean = np.mean(b)
        scoreVar = np.var(b)
        # boundaries
        c = np.array(boundaries)
        c1 = c/min(c)*100
        cdfBndMean = np.mean(c1)
        cdfBndVar =np.var(c1)
        bndMean = np.mean(c)
        bndVar = np.var(c)
        return([cdfCostMean,cdfCostVar,costMean,costVar,cdfScoreMean,cdfScoreVar,scoreMean,scoreVar,cdfBndMean,cdfBndVar,bndMean,bndVar])
    #
    #
    # adjust annealing iteration value
    #
    def adjustIterationValue(self,newItVal,projDir):

        inputFile = os.path.join(projDir,'input.dat')
        f = open(inputFile, 'r')
        inputData = f.readlines()
        f.close()
        outputData = []
        for line in inputData:
            if line.find('NUMITNS') > -1:
                outputData.append('NUMITNS %s\n' % int(newItVal))
            else:
                outputData.append(line)
        f = open(inputFile, 'w')
        f.writelines(outputData)
        f.close()
#
#
# generic functions
#
#
#
#
# set BLM value
#
def setBLM(newBLM,projDir):

    inputFile = os.path.join(projDir, 'input.dat')
    f = open(inputFile, 'r')
    inputData = f.readlines()
    f.close()
    outputData = []
    for line in inputData:
        if line.find('BLM') > -1:
            outputData.append('BLM %s\n' % formatAsME(newBLM))
        else:
            outputData.append(line)
    f = open(inputFile, 'w')
    f.writelines(outputData)
    f.close()
#
# formatAsME - format as Marxan Exponent format like 
#              Input File Editor
#
def formatAsME(inVal):
    outStr = "%.14E" % float(inVal)
    parts = outStr.split('E')
    sign = parts[1][:1]
    exponent = "%04d" % float(parts[1][1:])
    outStr = parts[0] + 'E' +  sign + exponent
    return(outStr)
#
#
# Run Marxan as process
# 
def runMarxanOnce(exeFile,workingDir,outDir,scenName,numReps):

    def writeLog(results,fName):
        f = open(logFName+'.stdout','w')
        stuff = results[0]
        if isinstance(stuff,str):
            f.write(stuff)
        elif isinstance(stuff,bytes):
            f.write(stuff.decode('utf-8'))
        f.close()

    # clear old results
    temp = [os.remove(outDir+'/'+i) for i in os.listdir(outDir)]
    # function variables
    debug = False
    printProgress = True
    abort = False
    currentRun = -1
    lastRun = currentRun
    loadStart = None
    runStart = None
    runFinish = None
    oldStatus = 'starting'
    status = 'load'
    startNotified = False
    pStat = None
    runPercent = 0.0
    lastPercent = 0.0
    messageText = ''
    abort = False

    loadStart = datetime.datetime.now()
    arcpy.AddMessage('Attempting to start Marxan')
    os.chdir(workingDir)
    si = subprocess.STARTUPINFO()
    si.dwFlags = subprocess.STARTF_USESTDHANDLES | subprocess.STARTF_USESHOWWINDOW
    proc = subprocess.Popen(exeFile,stdin=subprocess.PIPE,startupinfo=si)
    # wait
    time.sleep(5)
    logFName = os.path.join(outDir,scenName+'_log.dat')
    # look for log file to see if output directory is valid
    if os.path.exists(logFName):
        # read log to look for phrase indicating missing input files
        f = open(logFName,'r')
        logLines = f.readlines()
        f.close()
        InputsComplete = True
        for line in logLines:
            lText = line.lower()
            if 'aborting program' in lText:
                InputsComplete = False
        if InputsComplete:
            arcpy.AddMessage('Marxan started')
            while currentRun < numReps and not abort:
                f = open(logFName,'r')
                logLines = f.readlines()
                f.close()
                fileList = os.listdir(outDir)
                currentRun = sum([i.find(scenName+'_r')+1 for i in fileList])
                # check log file to see if things stopped for some reason 
                # we didn't detect otherwise such as changes to input file 
                # that were not passed to this function and are giving incorrect
                # progress count.
                # To resolve this we check to see if "The End" is found 
                # in the log file and if so change the currentRun value
                # to cause the code to exit the loop
                for line in logLines:
                    lText = line.lower()
                    if 'the end' in lText:
                        currentRun = numReps
                runStart = datetime.datetime.now()
                if status == 'load':
                    if oldStatus != status:
                        arcpy.AddMessage('Preprocessing inputs (NOTE:For large problems, this will take some time)')
                        oldStatus = status
                    if currentRun > 0:
                        status = 'run'
                        arcpy.AddMessage('Marxan running')
                if status == 'load' and not startNotified:
                    startNotified = True
                    f = open(logFName,'r')
                    logLines = f.readlines()
                    f.close()
                    for line in logLines:
                        if 'species cannot meet' in line:
                            abort = True
                            arcpy.AddMessage('Some species cannot meet targets. Check log file.')
                            messageText = 'Some species cannot meet targets. Check log file.'
                            try:
                                results = proc.terminate()
                            except:
                                pass 
                elif status == 'run' and lastRun != currentRun:
                    # progress update
                    runPercent = int(currentRun / float(numReps) * 100)
                    # limit signals to increase processing speed
                    if runPercent > lastPercent + 4:
                        if printProgress:
                            arcpy.AddMessage('%d%% repetitions complete' % runPercent)
                        lastPercent = runPercent
                        if abort:
                            break
                    lastRun = currentRun
                time.sleep(1)
                # check for status to find seg faults or other failures
                pStat = proc.poll()
                # Note: Marxan 2.4.3 requires user input to stop
                #       but Marxan 3.0.0 does not, so need to check for a return value of 0 (successful completion)
                if not pStat is None and pStat != 0:
                    abort = True
                    arcpy.AddMessage('Inputs failure. Check log file.')
                    try:
                        results = proc.communicate(input=b'\n')
                        writeLog(results,logFName+'.stdout')
                    except:
                        pass 
        else:
            arcpy.AddMessage('Load failure. Check log file.')
            abort = True
            results = proc.communicate(input=b'\n')
            writeLog(results,logFName+'.stdout')
            messageText = 'Check log file for information to identify the source of the problem. If source of problem is not clear then check input path, parameters and files.'
    else:
        #print('no log found')
        arcpy.AddMessage('System detected failure. Check output path and parameters.')
        proc.terminate()
        messageText = 'System detected failure. Check output path and parameters.'
        abort = True
    # if execution was successful...
    if not abort:
        # grab screen output and commit to disk because log file is not reliable
        runFinish = datetime.datetime.now()
        hasWarnings = False
        specCount = 0
        stdoutData, stderrData = proc.communicate(input=b'\n')
        logFName = os.path.join(outDir,scenName+'_log.dat')
        f = open(logFName,'r')
        logLines = f.readlines()
        f.close()
        # scan output for warnings or absence of features (species)
        for line in logLines:
            lText = line.lower()
            if 'abort' in lText or 'warning' in lText:
                hasWarnings = True
            if lText.find('species read in') > -1:
                temp = lText.strip()
                specCount = int(temp.split(' ')[0])
        # output summary and warnings
        messageText = 'Marxan execution completed\n'
        tt = time.strftime("%H:%M:%S", time.gmtime((runFinish-loadStart).seconds))
        lt = time.strftime("%H:%M:%S", time.gmtime((runStart-loadStart).seconds))
        rt = time.strftime("%H:%M:%S", time.gmtime((runFinish-runStart).seconds))
        messageText += 'Load time: %s\n' % lt
        messageText += 'Runs time: %s\n' % rt
        messageText += 'Total time: %s\n' % tt
        if hasWarnings:
            messageText += 'WARNING: The log file has warnings. Please check before using results!!\n'
        if specCount == 0:
            messageText += 'WARNING: Number of species registered appears to be zero. Check results and log file before using!\n'
        if hasWarnings == False and specCount > 0:
            messageText += 'No warnings or errors detected\n'
    if abort or hasWarnings:
        status = 'Error'
    else:
        status = 'Success'

    return(status,messageText)

